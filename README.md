<<<<<<< HEAD
# EncoderDecoder_CodeComment
"Empirical Evaluation of T5 and BART for Automated Code Comment Generation on Python and Java"
=======
# ðŸ“˜ Automated Code Comment Generation Using Large Language Models  
**Empirical Evaluation of T5 and BART for Python and Java**

---

## ðŸ§  Abstract

Source code documentation is critical to software maintenance and comprehension. Yet, it is often under-prioritized in real-world projects. This research investigates the automatic generation of source code comments using two powerful Large Language Models (LLMs): **T5** (by Google) and **BART** (by Meta AI).

We collected code-comment datasets from open-source Python and Java repositories and fine-tuned T5 and BART for generating meaningful code summaries. The models were evaluated using standard NLP metrics: **BLEU**, **Smoothed BLEU**, **ROUGE**, **METEOR**, and **SIDE similarity**.

---

## ðŸ“ Repository Structure

```
EncoderDecoder_CodeComment/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ environment.yaml               # Conda environment file
â”‚
â”œâ”€â”€ data_collection/              # Dataset builder
â”‚   â”œâ”€â”€ extract_python.py
â”‚   â”œâ”€â”€ extract_java.py
â”‚   â”œâ”€â”€ merge_and_clean.py
â”‚   â”œâ”€â”€ split_dataset.py
â”‚   â”œâ”€â”€ compare_test_data.py
â”‚   â”œâ”€â”€ raw_cloned_repos/         # Ignored: cloned GitHub repos
â”‚   â”œâ”€â”€ combined/
â”‚   â”œâ”€â”€ python_only/
â”‚   â”œâ”€â”€ java_only/
â”‚   â””â”€â”€ json_full_dataset.json
â”‚
â”œâ”€â”€ T5_codecomment_Model/
â”‚   â”œâ”€â”€ T5_codecomment_python_java/
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Tokenized_data/
â”‚   â”‚   â””â”€â”€ evaluation_results/
â”‚   â”œâ”€â”€ T5_codecomment_python/
â”‚   â””â”€â”€ T5_codecomment_java/
â”‚
â”œâ”€â”€ BART_codecomment_Model/
â”‚   â”œâ”€â”€ BART_codecomment_python_java/
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Tokenized_data/
â”‚   â”‚   â””â”€â”€ evaluation_results/
â”‚   â”œâ”€â”€ BART_codecomment_python/
â”‚   â””â”€â”€ BART_codecomment_java/
```

---

## ðŸ”§ Environment Setup

```bash
conda env create -f environment.yaml
conda activate codet5_bart
```

Required: Python 3.9+, PyTorch, Transformers, Datasets, SentenceTransformers, Evaluate, Scikit-learn.

---

## ðŸ“Š Dataset Preparation

```bash
cd data_collection

# Clone repos, extract Python + Java comments, and split
python extract_python.py
python extract_java.py
python merge_and_clean.py
python split_dataset.py
```

Datasets generated in:
- `data_collection/combined/`
- `data_collection/python_only/`
- `data_collection/java_only/`

---

## ðŸ—ï¸ Model Pipeline (T5 / BART)

Each model follows this 4-step pipeline:

### 1ï¸âƒ£ Tokenization  
```bash
cd T5_codecomment_Model/T5_codecomment_python_java/code
python tokenize_t5_dataset_python_java.py
```

### 2ï¸âƒ£ Model Training  
```bash
python modeltrain_t5_python_java.py   --train_dataset_path "../Tokenized_data/train"   --valid_dataset_path "../Tokenized_data/valid"   --output_base_dir ".."
```

### 3ï¸âƒ£ Inference  
```bash
python inference_t5_python_java.py   --model_dir "../models/T5_Finetuned_model"   --test_dataset_path "../../../data_collection/combined/test_data.json"   --output_base_dir "../results"
```

### 4ï¸âƒ£ Evaluation  
```bash
python evaluate_t5_python_java.py   --predictions_path "../results/t5_python_java_generated_comments.json"   --test_path "../../../data_collection/combined/test_data.json"   --output_dir "../results/evaluation"
```

---

## ðŸ“ˆ Evaluation Metrics

| Metric         | Description                                      |
|----------------|--------------------------------------------------|
| **BLEU**       | Measures n-gram precision                        |
| **Smoothed BLEU** | BLEU with smoothing for short sequences     |
| **ROUGE-1 / ROUGE-2 / ROUGE-L** | Measures overlap and sequence coverage |
| **METEOR**     | Weighted harmonic mean of precision and recall  |
| **SIDE**       | Semantic textual similarity using embeddings    |

---

## ðŸ§ª Experiments Conducted

- **Languages**: Python, Java
- **Model Types**: T5-base, BART-base
- **Comparisons**:
  - Python-only
  - Java-only
  - Combined dataset (Python + Java)

---

## ðŸ“Œ Notable Findings

- BART showed stronger syntactic fluency in short sequences.
- T5 exhibited stronger contextual consistency for longer functions.
- No-repeat n-gram and beam size tuning significantly impacted BLEU and ROUGE scores.

---

## ðŸ“ .gitignore Highlights

```bash
__pycache__/
*.py[cod]
*.log
*.ipynb_checkpoints
*.json
*.csv
.vscode/
.idea/
models/
results/
data_collection/raw_cloned_repos/
```

---

## ðŸ“œ License

This repository is for academic research and educational purposes. All datasets are collected from public open-source repositories on GitHub.

---

## ðŸ¤ Acknowledgments

- Google AI â€“ T5
- Meta AI â€“ BART
- Hugging Face Transformers
- GitHub Open-Source Community

---

## ðŸ§© Future Work

- Fine-tune on code-comment datasets like CodeSearchNet
- Introduce multilingual code models
- Evaluate with human annotators

---

## â­ Contribute or Cite

If you use or build on this project, feel free to open an issue or star the repo.
>>>>>>> 5038f93 (Initial commit: Project structure, code, README, environment, and .gitignore)
